---
phase: 01-foundation
plan: 04
type: execute
wave: 4
depends_on:
  - 01-03
files_modified:
  - src/ui/views/InboxView.tsx
  - src/ui/views/SectionView.tsx
  - src/ui/views/StorageWarning.tsx
  - src/ui/views/CaptureOverlay.tsx
  - src/ui/components/AtomCard.tsx
  - src/ui/components/AtomTypeIcon.tsx
  - src/ui/components/SectionItemList.tsx
  - src/ui/components/VoiceCapture.tsx
  - src/ui/layout/MainPane.tsx
  - src/storage/classification-log.ts
  - src/app.tsx
autonomous: false
requirements:
  - TRST-02
  - TRST-04
  - ORG-09

must_haves:
  truths:
    - "User can create a new atom via the capture overlay triggered by Ctrl+N or FAB button"
    - "Created atoms appear in the correct section view and persist across page refresh"
    - "User can undo a recent atom mutation via Ctrl+Z and the atom reverts"
    - "User can export all data as JSON and Markdown via export button"
    - "Storage persistence warning appears if browser denies persistent storage"
    - "Inbox shows one item at a time in card-by-card triage mode with swipe gestures"
    - "During triage, system suggests an atom type based on content heuristics and user confirms or changes with one tap"
    - "During triage, type-ahead search lets user search for projects/areas to link the atom"
    - "Swiping left on atom rows archives, swiping right completes"
    - "Classification events are logged for future pattern learning"
  artifacts:
    - path: "src/ui/views/InboxView.tsx"
      provides: "Card-by-card triage with swipe gestures, type-ahead linking, and type suggestion"
      min_lines: 80
    - path: "src/ui/views/CaptureOverlay.tsx"
      provides: "Quick capture overlay with text input and optional voice button"
      min_lines: 30
    - path: "src/ui/components/AtomCard.tsx"
      provides: "Compact atom row with swipe gestures (left=archive, right=complete)"
      min_lines: 40
    - path: "src/ui/components/VoiceCapture.tsx"
      provides: "Web Speech API voice-to-text with feature detection and graceful degradation"
      min_lines: 30
    - path: "src/ui/views/StorageWarning.tsx"
      provides: "Full-screen persistence warning with platform-specific instructions"
      min_lines: 20
    - path: "src/storage/classification-log.ts"
      provides: "Stores classification events for future pattern learning"
      contains: "logClassification"
  key_links:
    - from: "src/ui/views/InboxView.tsx"
      to: "src/ui/signals/store.ts"
      via: "Reads inboxItems from store, dispatches CLASSIFY_INBOX_ITEM"
      pattern: "dispatch"
    - from: "src/ui/views/InboxView.tsx"
      to: "src/storage/classification-log.ts"
      via: "Logs classification event on each triage action"
      pattern: "logClassification"
    - from: "src/ui/views/CaptureOverlay.tsx"
      to: "src/ui/signals/store.ts"
      via: "Dispatches CREATE_INBOX_ITEM command"
      pattern: "dispatch"
    - from: "src/ui/components/AtomCard.tsx"
      to: "src/ui/signals/store.ts"
      via: "Swipe gestures dispatch UPDATE_ATOM (archive/complete)"
      pattern: "dispatch"
    - from: "src/ui/layout/MainPane.tsx"
      to: "src/ui/views/InboxView.tsx"
      via: "Routes activePage='inbox' to InboxView"
      pattern: "InboxView"
---

<objective>
Build all UI views and interactive components with full implementation of locked user decisions: card-by-card inbox triage with swipe gestures, type-ahead search for linking, content-based type suggestion, swipe-to-archive/complete on atom rows, fast capture overlay with voice support, and classification event logging for future pattern learning.

Purpose: This plan fills the shell frame (built in 01-03) with all the interactive views and components that make Phase 1 shippable. It implements every locked CONTEXT.md decision for the inbox/classify flow and binder UI interactions. The card-by-card triage flow is the core UX differentiator -- it forces decisions (no snooze), rewards completion (micro-animations), and makes classification fast (type suggestion + type-ahead linking).

Output: Complete set of views (InboxView, SectionView, CaptureOverlay, StorageWarning) and components (AtomCard, AtomTypeIcon, SectionItemList, VoiceCapture) with all user-facing interactions functional. Classification events logged for future pattern learning.
</objective>

<execution_context>
@C:/Users/patri/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/patri/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-CONTEXT.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
@.planning/phases/01-foundation/01-02-SUMMARY.md
@.planning/phases/01-foundation/01-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build views and components with card-by-card triage, swipe gestures, type-ahead, and type suggestion</name>
  <files>
    src/ui/views/InboxView.tsx
    src/ui/views/SectionView.tsx
    src/ui/views/StorageWarning.tsx
    src/ui/components/AtomCard.tsx
    src/ui/components/AtomTypeIcon.tsx
    src/ui/components/SectionItemList.tsx
    src/ui/layout/MainPane.tsx
  </files>
  <action>
Per CONTEXT.md locked decisions: Card-by-card triage (one inbox item at a time, fullscreen-ish, Tinder-like swipe on mobile), swipe gestures on atom rows (left=archive, right=complete), type-ahead search for linking during triage, system suggests atom type based on content, micro-animation rewards on triage completion. These are NON-NEGOTIABLE locked decisions.

1. Create `src/ui/components/AtomTypeIcon.tsx`:
   - Small colored icon/indicator for each atom type using the signature colors from colors.ts
   - task: checkmark icon (blue #58a6ff), fact: book (green #3fb950), event: calendar (amber #d29922), decision: compass (purple #bc8cff), insight: lightbulb (pink #f778ba)
   - Use simple inline SVG icons (no icon library dependency)
   - Export as a component accepting `type: AtomType` prop
   - Do NOT destructure props -- use `props.type`

2. Create `src/ui/components/AtomCard.tsx` with swipe gestures per CONTEXT.md locked decision:
   - Compact row display by default (hybrid density per user decision):
     - Left: colored type indicator (AtomTypeIcon)
     - Title text, truncated status badge
     - Subtle timestamp (relative "2h ago")
   - On click: expand inline to show full content (plain text for now)
   - **Swipe gestures (LOCKED DECISION):** Use solid-gesture (installed in Plan 01-01) or raw touch handlers:
     - Swipe LEFT: archive the atom (dispatch UPDATE_ATOM with status='archived')
     - Swipe RIGHT: complete the atom (dispatch UPDATE_ATOM with status='done')
     - Visual feedback: card slides in swipe direction with color tint (red for archive, green for complete)
     - Velocity threshold: trigger at 80px displacement or 0.5 velocity
     - On mobile: must disambiguate from scroll (only horizontal swipes trigger, vertical initiates scroll)
   - Use `<For>` for lists, do NOT destructure props

3. Create `src/ui/components/SectionItemList.tsx`:
   - List of SectionItems (e.g., "Project: Kitchen Reno", "Area: Health") for the active section
   - Each item clickable to filter atoms by sectionItemId
   - "Add" button to create new section item (dispatches CREATE_SECTION_ITEM command)
   - Rename on double-click or long-press (dispatches RENAME_SECTION_ITEM)
   - Archive action (dispatches ARCHIVE_SECTION_ITEM)

4. Create `src/ui/views/InboxView.tsx` with card-by-card triage (LOCKED DECISION):
   - **Card-by-card mode (NOT a list):** Show ONE inbox item at a time, fullscreen-ish card layout
   - Current inbox item displayed as a large card in the center of the viewport:
     - Title (if present) at top
     - Content preview (markdown rendered as plain text for v1)
     - Created timestamp
   - **Swipe gestures on triage card (Tinder-like on mobile):**
     - Swipe LEFT: discard/skip (move to next without classifying -- item stays in inbox)
     - Swipe RIGHT: classify (opens classification panel below/beside the card)
     - Swipe UP: quick-archive (dispatch UPDATE_ATOM with status='archived' after classifying as generic type)
   - **System suggests atom type (LOCKED DECISION):**
     - Simple content-based heuristic (NOT AI -- that's deferred):
       - Contains "todo", "buy", "fix", "call", "email", "schedule", "remind", deadline-like patterns -> suggest "task"
       - Contains "meeting", "appointment", date/time patterns, "on [day]" -> suggest "event"
       - Contains "decided", "going with", "chose", "will use" -> suggest "decision"
       - Contains "realized", "idea", "what if", "maybe", "could" -> suggest "insight"
       - Default fallback: suggest "fact"
     - Pre-select the suggested type with a highlighted button; other types shown as unselected alternatives
     - User confirms with one tap or changes type with one tap on a different button
   - **Type-ahead search for linking (LOCKED DECISION):**
     - Below the type selector, a text input labeled "Link to..." with type-ahead search
     - As user types, filter sectionItems by name (case-insensitive substring match)
     - Show matching sectionItems as a dropdown list
     - Selecting a sectionItem sets the sectionItemId on the classified atom
     - This allows the user to quickly link "Buy groceries" to the "Home" area or "Kitchen Reno" project
   - **Classification action:**
     - "Classify" button (or right-swipe confirm) sends CLASSIFY_INBOX_ITEM with { id, type, sectionItemId }
     - On successful classification: micro-animation reward (checkmark animation or card flies off screen with a satisfying transition per CONTEXT.md)
     - Auto-advance to next inbox item
   - **Empty state:** When inbox is empty, show celebratory message: "Inbox zero! All items classified." with subtle animation
   - **Counter:** Show "3 of 12" progress indicator at top
   - **No snooze** per CONTEXT.md -- there is no skip-and-defer button. User must classify or discard.

5. Create `src/ui/views/SectionView.tsx`:
   - Shows atoms filtered by the active section (and optionally by section item)
   - Uses `<For>` with AtomCard components (which have swipe gestures built in)
   - Empty state: contextual hint ("No items yet. Capture a thought!")

6. Create `src/ui/views/StorageWarning.tsx`:
   - Full-screen overlay shown when persistence is denied (per user decision: prominent first-run warning)
   - Explains data risk: "Your data may be deleted by the browser after 7 days of inactivity"
   - Instructions: "Add this app to your Home Screen" for Safari/iOS, "Allow storage persistence" for other browsers
   - Dismissable (stores dismissal in config table via Worker dispatch) but re-shows if persistence status changes
   - Only shown on first launch if persistence denied. Not blocking -- the user can dismiss and continue.

7. Update `src/ui/layout/MainPane.tsx`:
   - Replace placeholder divs from Plan 01-03 with real view components
   - Routes based on activePage: 'inbox' -> InboxView, 'section' -> SectionView, 'all' -> all atoms view (SectionView with no filter)
   - Import and render InboxView, SectionView, StorageWarning

CRITICAL SolidJS rules:
- Never destructure props: use `props.atom`, not `const { atom } = props`
- Use `<For>` for lists, not `.map()`
- Use `<Show>` for conditional rendering
  </action>
  <verify>
1. `pnpm lint` passes on all view and component files
2. `pnpm build` succeeds
3. `pnpm dev` -- open in browser:
   - InboxView shows card-by-card triage (one item at a time, not a list)
   - Type suggestion pre-selects a type based on content (e.g., "Buy groceries" -> task)
   - Type-ahead search filters section items as you type
   - Classifying an item shows micro-animation, advances to next card
   - AtomCard in SectionView has swipe gestures (left=archive, right=complete)
   - StorageWarning appears if persistence is denied
4. Create 3 inbox items with varied content, triage each one:
   - "Buy groceries" should suggest "task"
   - "Meeting with John on Friday" should suggest "event"
   - "I realized the API is wrong" should suggest "insight"
5. After triaging all items, empty state shows "Inbox zero" message
  </verify>
  <done>
All views and components render with locked CONTEXT.md decisions implemented: card-by-card triage with swipe gestures (Tinder-like on mobile), content-based type suggestion (heuristic, one-tap confirm), type-ahead search for linking atoms to section items, swipe-to-archive/complete on atom rows, micro-animation rewards on triage completion, storage persistence warning. MainPane routes to real views.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement fast capture overlay, voice capture, keyboard shortcuts, and classification event logging</name>
  <files>
    src/ui/views/CaptureOverlay.tsx
    src/ui/components/VoiceCapture.tsx
    src/storage/classification-log.ts
    src/app.tsx
  </files>
  <action>
Per CONTEXT.md locked decisions: Instant capture mechanism that prioritizes speed above all. Voice capture via Web Speech API with mic button inside the capture overlay. Voice transcripts land as raw text. No smart parsing in v1. Pattern learning -- track classification patterns over time to improve suggestions.

1. Create `src/storage/classification-log.ts` for pattern learning (CONTEXT.md locked decision):
   - `ClassificationEvent` type: { inboxItemId: string; content: string; suggestedType: AtomType; chosenType: AtomType; sectionItemId: string | null; sectionItemName: string | null; timestamp: number }
   - `logClassification(event: ClassificationEvent): void` -- stores in Dexie config table under key 'classification-events' as a JSON array appended to. Uses writeQueue.enqueue.
   - `getClassificationHistory(): Promise<ClassificationEvent[]>` -- reads from config table.
   - `suggestTypeFromPatterns(content: string): AtomType | null` -- looks at recent classification history, finds items with similar content keywords, returns the most common chosenType if pattern confidence > 60% (at least 3 similar items classified the same way). Returns null if no strong pattern found (falls back to content heuristic in InboxView).
   - This is a lightweight foundation for the "Pattern learning" locked decision. It stores the data needed for future AI-powered suggestions without requiring AI now.

2. Create `src/ui/views/CaptureOverlay.tsx`:
   - Modal overlay that slides up from bottom on mobile, centers on desktop
   - Dark theme consistent with shell (#161b22 background, #30363d border)
   - Large text input (textarea) that auto-focuses on open -- user starts typing immediately
   - Optional title field above the textarea (collapsed by default, expandable)
   - "Save to Inbox" button -- dispatches CREATE_INBOX_ITEM with content and optional title
   - Mic button next to the text input -- toggles voice capture (VoiceCapture component)
   - Keyboard shortcuts inside overlay:
     - Enter (with Ctrl/Cmd) or dedicated button: save and close
     - Escape: close without saving
   - Micro-animation on save: subtle checkmark animation or fade-out confirmation per user decision (micro-animation rewards)
   - Overlay closes after successful save

3. Create `src/ui/components/VoiceCapture.tsx`:
   - Feature-detect Web Speech API: `'SpeechRecognition' in window || 'webkitSpeechRecognition' in window`
   - If not available: render nothing (graceful degradation -- mic button hidden)
   - If available: mic button toggles recording state
   - On start: create SpeechRecognition instance, set continuous: false, interimResults: true, lang: 'en-US'
   - Display interim results in real-time below the main textarea (or inline)
   - On final result: append transcript text to the capture overlay's textarea content
   - Show small disclaimer text near mic button: "Voice sent to browser speech service" (per RESEARCH.md -- Web Speech API is NOT offline)
   - Handle errors gracefully: if mic permission denied, show "Microphone access required" message
   - On iOS standalone PWA: may not work -- feature-detect and hide if unavailable

4. Update `src/app.tsx` to add capture overlay and keyboard shortcuts:
   - Add capture overlay state: [showCapture, setShowCapture] createSignal
   - Add StorageWarning overlay logic: show if persistence denied and not previously dismissed
   - Global keydown listener (attached to document):
     - Ctrl+N / Cmd+N: preventDefault, open CaptureOverlay (or toggle if already open)
     - Ctrl+Z / Cmd+Z: preventDefault, dispatch UNDO command (already wired in 01-03, verify still works)
     - Escape: close CaptureOverlay if open, close StorageWarning if open
   - Add a floating action button (FAB) in bottom-right corner (above status bar) for mobile users who can't use keyboard shortcuts -- tapping opens CaptureOverlay
   - The FAB should be a "+" icon, themed with the primary accent color, with slight elevation shadow
   - Render CaptureOverlay conditionally with `<Show when={showCapture()}>`
   - Render StorageWarning conditionally based on persistence status

5. Wire classification event logging into InboxView:
   - After each successful classification in InboxView (Task 1), call logClassification() with the classification event data
   - Before suggesting a type in InboxView, call suggestTypeFromPatterns() first; if it returns a result, use that instead of the content heuristic

IMPORTANT: The capture flow must be FAST. Open overlay -> type -> save must take under 3 seconds for a short thought. No unnecessary fields, no mandatory classification at capture time. Classification happens in triage (InboxView).
  </action>
  <verify>
1. `pnpm lint` passes on capture overlay, voice capture, and classification log files
2. `pnpm build` succeeds
3. In browser: press Ctrl+N -- overlay appears instantly with focused textarea
4. Type "Test thought" and press Ctrl+Enter -- item appears in inbox, overlay closes
5. On Chrome: mic button visible, clicking starts recording, speaking produces text in textarea
6. On Firefox: mic button hidden (Web Speech API not supported)
7. FAB button visible on mobile viewport -- tapping opens overlay
8. Escape closes overlay without saving
9. Classify an inbox item -- verify classification event logged in config table (DevTools -> IndexedDB -> config -> classification-events)
10. Classify 4+ items with "buy..." content as "task" -- verify suggestTypeFromPatterns returns "task" for next "buy..." item
  </verify>
  <done>
Fast capture overlay opens instantly via Ctrl+N or FAB button. User types content, saves to inbox with Ctrl+Enter or button. Voice capture available in supported browsers (Chrome, Safari) with real-time transcription. Mic button hidden in unsupported browsers. Save triggers micro-animation confirmation. Total capture time for a short thought is under 3 seconds. Classification events logged for pattern learning. Pattern-based type suggestion falls back to content heuristic when insufficient data.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Verify complete Phase 1 functionality</name>
  <files>
    src/app.tsx
  </files>
  <action>
Human verification of the complete Phase 1 build. All automated work is done in Tasks 1-2 of this plan and Plans 01-01 through 01-03. This checkpoint confirms the integrated system works end-to-end from a user perspective.
  </action>
  <verify>
1. Run `pnpm dev` and open the app in Chrome

2. First-run experience:
   - App loads with dark theme (#0d1117 background)
   - If storage persistence denied: full-screen warning appears explaining data risk
   - Dismiss warning, see empty binder with four sections in sidebar

3. Capture flow (speed test):
   - Press Ctrl+N -- overlay appears instantly
   - Type "Buy groceries" and press Ctrl+Enter
   - Item appears in Inbox tab
   - Total time: under 3 seconds

4. Card-by-card triage flow:
   - Go to Inbox tab -- see single card with "Buy groceries" (NOT a list)
   - System should pre-suggest "task" type (blue highlight)
   - Type-ahead search: type "Home" in link field, see matching section items
   - Tap "task" to confirm type, select a section item, tap Classify
   - Micro-animation plays, card advances (or shows "Inbox zero" if last item)

5. Create more items and test type suggestion:
   - "Meeting with John on Friday" -- should suggest "event"
   - "I realized we should use Rust" -- should suggest "insight"
   - "Decided to go with Plan B" -- should suggest "decision"

6. Swipe gestures on atom rows:
   - Go to a section view with atoms
   - On mobile viewport (DevTools device mode): swipe left on an atom row -- atom archives
   - Swipe right on an atom row -- atom completes

7. Persistence test:
   - Create 2-3 atoms of different types
   - Hard refresh the page (F5)
   - All atoms still present

8. Undo test:
   - Create an atom
   - Press Ctrl+Z
   - Atom is removed (undo of create)

9. Export test:
   - Click export button (or trigger via status bar)
   - JSON file downloads with all atoms
   - Verify file contains the atoms you created

10. Mobile test (Chrome DevTools device mode):
    - Toggle to mobile viewport (e.g., iPhone 14)
    - Sidebar hidden, bottom tab bar visible with 4 section icons
    - Page tab strip scrollable horizontally
    - Status bar visible above bottom tab bar
    - FAB button visible for capture
    - Card-by-card triage works with touch swipe gestures

11. Status bar check:
    - Status bar shows: persistence status (green/red dot), atom count, inbox count
    - Values update reactively as you create/classify atoms

12. Voice capture (Chrome only):
    - Open capture overlay, click mic button
    - Speak a phrase -- text appears in textarea
    - Save the transcribed text to inbox

13. Pattern learning check:
    - Classify 4+ items starting with "buy" as "task"
    - Create a new "buy batteries" inbox item
    - Verify triage suggests "task" (from learned pattern, not just content heuristic)
  </verify>
  <done>
All Phase 1 success criteria verified by user: atoms can be created, classified, persisted, undone, and exported. Dark-themed binder UI with responsive layout works on desktop and mobile. Card-by-card triage with swipe gestures, type suggestion, and type-ahead linking functional. Fast capture under 3 seconds. Storage persistence flow functional. Voice capture works in supported browsers. Classification events logged for pattern learning.
  </done>
</task>

</tasks>

<verification>
1. `pnpm build:all` succeeds (WASM + Vite build)
2. `pnpm lint` passes across entire codebase
3. App loads with dark theme and binder layout
4. Four sections visible: Projects, Areas, Resources, Archive
5. Card-by-card inbox triage with swipe gestures, type suggestion, type-ahead linking
6. Atoms can be created, classified, persisted, and undone
7. Swipe left on atom rows archives, swipe right completes
8. Export produces valid JSON with all atoms
9. Storage persistence requested and status shown in status bar
10. Mobile layout correct with bottom tabs and safe area insets
11. Fast capture under 3 seconds from trigger to save
12. Classification events logged for pattern learning
</verification>

<success_criteria>
- Card-by-card inbox triage shows one item at a time (not a list), with swipe gestures for classify/skip
- System suggests atom type based on content heuristics and learned patterns
- Type-ahead search for linking atoms to section items during triage
- Swipe left on atom rows archives, swipe right completes (solid-gesture or raw touch)
- Fast capture overlay triggered by Ctrl+N or FAB, saves to inbox instantly
- Voice capture works in Chrome/Safari, hidden in Firefox
- Micro-animation rewards on triage completion
- Classification events stored for future pattern learning
- Storage persistence warning shown on denial
- Page refresh preserves all data
- Export downloads JSON backup file
- Undo (Ctrl+Z) reverts the most recent mutation
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-04-SUMMARY.md`
</output>
