/**
 * GTD next-action analysis — multi-step decision tree via local LLM.
 *
 * Walks an atom through the GTD flowchart:
 *   actionable? → no → reference-or-trash?
 *   actionable? → yes → single-or-multi?
 *     single → 2-min rule? → yes → "do it now"
 *     single → 2-min rule? → no → delegate? → yes → waiting
 *     single → 2-min rule? → no → delegate? → no → defer → next-action
 *     multi → "this is a project" → next-action (for the first step)
 *
 * Each step: LLM generates a contextual question with 2-4 options.
 * Hardcoded fallback questions guarantee the flow works without AI.
 *
 * Pure module: no imports from store.ts — all state passed in by caller.
 *
 * Phase 7: GTD analysis skill agent
 */

import type { Atom } from '../types/atoms';
import { dispatchAI } from './router';

// --- GTD step types ---

export type GTDStepId =
  | 'actionable'
  | 'reference-or-trash'
  | 'single-or-multi'
  | 'two-min-rule'
  | 'delegate'
  | 'defer'
  | 'next-action'
  | 'done'; // terminal

export interface GTDOption {
  id: string;
  label: string;
  description?: string;
}

export interface GTDStep {
  stepId: GTDStepId;
  question: string;
  options: GTDOption[];
  /** Whether this step was generated by AI or fell back to hardcoded */
  aiGenerated: boolean;
}

export interface GTDAnswer {
  stepId: GTDStepId;
  selectedOptionId: string;
  selectedLabel: string;
}

/** The final recommendation produced after completing the decision tree. */
export interface GTDRecommendation {
  /** Suggested next action text (new title or content update) */
  nextActionText: string;
  /** Suggested status change */
  suggestedStatus?: 'open' | 'in-progress' | 'waiting' | 'done' | 'cancelled' | 'archived';
  /** Suggested energy level */
  suggestedEnergy?: 'Quick' | 'Medium' | 'Deep';
  /** Suggested context tag */
  suggestedContext?: string;
  /** Suggested tags to add */
  suggestedTags?: string[];
  /** One-sentence reasoning from the AI */
  reasoning: string;
  /** Whether the AI generated this or it was fallback-derived */
  aiGenerated: boolean;
}

// --- JSON schemas for XGrammar-constrained output ---

const STEP_RESPONSE_SCHEMA = {
  type: 'object',
  properties: {
    question: { type: 'string' },
    options: {
      type: 'array',
      items: {
        type: 'object',
        properties: {
          id: { type: 'string' },
          label: { type: 'string' },
          description: { type: 'string' },
        },
        required: ['id', 'label'],
      },
      minItems: 2,
      maxItems: 4,
    },
  },
  required: ['question', 'options'],
};

const RECOMMENDATION_SCHEMA = {
  type: 'object',
  properties: {
    nextActionText: { type: 'string' },
    suggestedStatus: { type: 'string', enum: ['open', 'in-progress', 'waiting', 'done', 'cancelled', 'archived'] },
    suggestedEnergy: { type: 'string', enum: ['Quick', 'Medium', 'Deep'] },
    suggestedContext: { type: 'string' },
    suggestedTags: { type: 'array', items: { type: 'string' } },
    reasoning: { type: 'string' },
  },
  required: ['nextActionText', 'reasoning'],
};

// --- Branching logic ---

/**
 * Determine the next step based on the current step and selected option.
 */
export function determineNextStep(stepId: GTDStepId, selectedOptionId: string): GTDStepId {
  switch (stepId) {
    case 'actionable':
      return selectedOptionId === 'yes' ? 'single-or-multi' : 'reference-or-trash';

    case 'reference-or-trash':
      // Terminal — reference → archive, trash → cancel
      return 'done';

    case 'single-or-multi':
      return selectedOptionId === 'single' ? 'two-min-rule' : 'next-action'; // multi → project, ask for first next-action

    case 'two-min-rule':
      return selectedOptionId === 'yes' ? 'done' : 'delegate'; // yes → do it now (done)

    case 'delegate':
      return selectedOptionId === 'yes' ? 'done' : 'defer'; // yes → waiting (done)

    case 'defer':
      return 'next-action';

    case 'next-action':
      return 'done';

    default:
      return 'done';
  }
}

/**
 * Derive terminal outcome from the answer trail (used for fallback recommendation).
 */
export function deriveOutcome(answers: GTDAnswer[]): {
  status: 'open' | 'waiting' | 'done' | 'archived' | 'cancelled';
  isProject: boolean;
} {
  const answerMap = new Map(answers.map(a => [a.stepId, a.selectedOptionId]));

  // Not actionable
  if (answerMap.get('actionable') === 'no') {
    const refOrTrash = answerMap.get('reference-or-trash');
    if (refOrTrash === 'trash') return { status: 'cancelled', isProject: false };
    return { status: 'archived', isProject: false };
  }

  // Multi-step → project
  const isProject = answerMap.get('single-or-multi') === 'multi';

  // 2-min rule → do it now
  if (answerMap.get('two-min-rule') === 'yes') return { status: 'done', isProject };

  // Delegate → waiting
  if (answerMap.get('delegate') === 'yes') return { status: 'waiting', isProject };

  // Default: next action is open
  return { status: 'open', isProject };
}

// --- Fallback questions ---

const FALLBACK_QUESTIONS: Record<GTDStepId, GTDStep> = {
  'actionable': {
    stepId: 'actionable',
    question: 'Is this item actionable? Can you do something about it?',
    options: [
      { id: 'yes', label: 'Yes, it\'s actionable', description: 'There\'s a concrete action I can take' },
      { id: 'no', label: 'No, it\'s not actionable', description: 'It\'s reference material, someday/maybe, or trash' },
    ],
    aiGenerated: false,
  },
  'reference-or-trash': {
    stepId: 'reference-or-trash',
    question: 'Should this be kept as reference or discarded?',
    options: [
      { id: 'reference', label: 'Keep as reference', description: 'Archive it for future lookup' },
      { id: 'trash', label: 'Discard it', description: 'It\'s no longer relevant' },
    ],
    aiGenerated: false,
  },
  'single-or-multi': {
    stepId: 'single-or-multi',
    question: 'Is this a single action or a multi-step project?',
    options: [
      { id: 'single', label: 'Single action', description: 'One clear next step' },
      { id: 'multi', label: 'Multi-step project', description: 'Requires multiple actions to complete' },
    ],
    aiGenerated: false,
  },
  'two-min-rule': {
    stepId: 'two-min-rule',
    question: 'Can this be done in under 2 minutes?',
    options: [
      { id: 'yes', label: 'Yes, under 2 minutes', description: 'Quick enough to do right now' },
      { id: 'no', label: 'No, it takes longer', description: 'Needs to be scheduled or delegated' },
    ],
    aiGenerated: false,
  },
  'delegate': {
    stepId: 'delegate',
    question: 'Should this be delegated to someone else?',
    options: [
      { id: 'yes', label: 'Yes, delegate it', description: 'Someone else should handle this' },
      { id: 'no', label: 'No, I\'ll do it', description: 'I\'m the right person for this' },
    ],
    aiGenerated: false,
  },
  'defer': {
    stepId: 'defer',
    question: 'When should this be done?',
    options: [
      { id: 'today', label: 'Today', description: 'Add to today\'s next actions' },
      { id: 'this-week', label: 'This week', description: 'Schedule for this week' },
      { id: 'someday', label: 'Someday/maybe', description: 'No urgency — review later' },
    ],
    aiGenerated: false,
  },
  'next-action': {
    stepId: 'next-action',
    question: 'What is the very next physical action?',
    options: [
      { id: 'keep', label: 'Keep current title', description: 'The title already describes the next action' },
      { id: 'refine', label: 'Refine the action', description: 'Let AI suggest a clearer next action' },
    ],
    aiGenerated: false,
  },
  'done': {
    stepId: 'done',
    question: '',
    options: [],
    aiGenerated: false,
  },
};

// --- Prompt builders ---

function buildAtomContext(atom: Atom, relatedAtoms: Atom[]): string {
  const related = relatedAtoms.length > 0
    ? `\nRELATED ITEMS:\n${relatedAtoms.map(a => `- ${a.title} (${a.type}, ${a.status})`).join('\n')}`
    : '';

  return `ITEM TO ANALYZE:
Title: ${atom.title}
Content: ${atom.content}
Type: ${atom.type}
Status: ${atom.status}
Energy: ${atom.energy ?? 'unset'}
Context: ${atom.context ?? 'none'}
Tags: ${atom.tags?.join(', ') || 'none'}${related}`;
}

function buildStepPrompt(
  stepId: GTDStepId,
  atomContext: string,
  answerHistory: GTDAnswer[],
): string {
  const historyText = answerHistory.length > 0
    ? `\nPREVIOUS ANSWERS:\n${answerHistory.map(a => `- ${a.stepId}: ${a.selectedLabel}`).join('\n')}`
    : '';

  const stepInstructions: Record<GTDStepId, string> = {
    'actionable': 'Ask whether this item is actionable — can the user take a concrete physical action on it? Consider the item\'s content and context.',
    'reference-or-trash': 'The item is not actionable. Ask whether it should be kept as reference material or discarded entirely.',
    'single-or-multi': 'The item is actionable. Ask whether it requires a single action or is a multi-step project that needs breaking down.',
    'two-min-rule': 'This is a single action. Ask whether it can be completed in under 2 minutes (the GTD 2-minute rule).',
    'delegate': 'This action takes more than 2 minutes. Ask whether it should be delegated to someone else or if the user should do it themselves.',
    'defer': 'The user will do this themselves. Ask when it should be done — today, this week, or someday/maybe.',
    'next-action': 'Ask the user to define the very next physical action. Suggest a concrete, verb-first action based on the item content.',
    'done': '',
  };

  return `You are a GTD (Getting Things Done) productivity coach analyzing a user's item.

${atomContext}
${historyText}

CURRENT STEP: ${stepId}
INSTRUCTION: ${stepInstructions[stepId]}

Generate a contextual question with 2-4 multiple-choice options tailored to this specific item.
Make the question and options reference the item's actual content — don't be generic.
Each option needs an "id" (short identifier), "label" (button text), and optionally "description" (brief explanation).

Respond with ONLY valid JSON:
{"question":"<your contextual question>","options":[{"id":"<id>","label":"<label>","description":"<desc>"},...]}`;
}

function buildRecommendationPrompt(
  atomContext: string,
  answers: GTDAnswer[],
): string {
  const historyText = answers.map(a => `- ${a.stepId}: ${a.selectedLabel}`).join('\n');

  return `You are a GTD (Getting Things Done) productivity coach. Based on the analysis below, recommend changes to this item.

${atomContext}

GTD ANALYSIS ANSWERS:
${historyText}

Recommend:
1. nextActionText: A clear, verb-first next physical action (or the current title if it's already good)
2. suggestedStatus: The appropriate status (open, in-progress, waiting, done, cancelled, archived)
3. suggestedEnergy: Energy level needed (Quick, Medium, Deep)
4. suggestedContext: Where/when to do this (e.g., "@computer", "@phone", "@errands", "@office")
5. suggestedTags: Relevant tags as an array
6. reasoning: One sentence explaining your recommendation

Respond with ONLY valid JSON.`;
}

// --- Step execution ---

/** Module-level AbortController for cancellation. */
let gtdAbortController: AbortController | null = null;

/**
 * Execute a single GTD step — dispatches to AI, falls back to hardcoded question.
 *
 * @param stepId - Current step in the GTD decision tree
 * @param atom - The atom being analyzed
 * @param relatedAtoms - Related atoms for context
 * @param answerHistory - Previous Q&A answers
 * @param signal - AbortSignal for cancellation
 * @returns The GTD step with question and options
 */
export async function executeGTDStep(
  stepId: GTDStepId,
  atom: Atom,
  relatedAtoms: Atom[],
  answerHistory: GTDAnswer[],
  signal?: AbortSignal,
): Promise<GTDStep> {
  // Terminal step — no question needed
  if (stepId === 'done') return FALLBACK_QUESTIONS['done'];

  const fallback = FALLBACK_QUESTIONS[stepId];

  try {
    const atomContext = buildAtomContext(atom, relatedAtoms);
    const prompt = buildStepPrompt(stepId, atomContext, answerHistory);

    const response = await dispatchAI({
      requestId: crypto.randomUUID(),
      prompt,
      maxTokens: 300,
      jsonSchema: STEP_RESPONSE_SCHEMA,
      signal,
    });

    const parsed = parseStepResponse(response.text);
    if (parsed) {
      return {
        stepId,
        question: parsed.question,
        options: parsed.options,
        aiGenerated: true,
      };
    }
  } catch {
    // AI failed — use fallback
  }

  return fallback;
}

/**
 * Generate a final recommendation from the complete answer trail.
 */
export async function generateRecommendation(
  atom: Atom,
  relatedAtoms: Atom[],
  answers: GTDAnswer[],
  signal?: AbortSignal,
): Promise<GTDRecommendation> {
  const fallbackOutcome = deriveOutcome(answers);

  try {
    const atomContext = buildAtomContext(atom, relatedAtoms);
    const prompt = buildRecommendationPrompt(atomContext, answers);

    const response = await dispatchAI({
      requestId: crypto.randomUUID(),
      prompt,
      maxTokens: 400,
      jsonSchema: RECOMMENDATION_SCHEMA,
      signal,
    });

    const parsed = parseRecommendation(response.text);
    if (parsed) {
      return { ...parsed, aiGenerated: true };
    }
  } catch {
    // AI failed — derive from answers
  }

  // Fallback recommendation from answer trail
  return {
    nextActionText: atom.title,
    suggestedStatus: fallbackOutcome.status,
    reasoning: fallbackOutcome.isProject
      ? 'This is a multi-step project. The next action keeps the current title.'
      : `Based on your GTD analysis, this item should be ${fallbackOutcome.status}.`,
    aiGenerated: false,
  };
}

// --- Response parsers ---

function parseStepResponse(text: string): { question: string; options: GTDOption[] } | null {
  try {
    const match = text.match(/\{[\s\S]*\}/);
    if (!match) return null;
    const parsed = JSON.parse(match[0]) as Record<string, unknown>;
    if (typeof parsed.question !== 'string') return null;
    if (!Array.isArray(parsed.options) || parsed.options.length < 2) return null;

    const options = (parsed.options as Record<string, unknown>[])
      .filter(o => typeof o.id === 'string' && typeof o.label === 'string')
      .map(o => ({
        id: o.id as string,
        label: o.label as string,
        description: typeof o.description === 'string' ? o.description : undefined,
      }));

    if (options.length < 2) return null;
    return { question: parsed.question, options };
  } catch {
    return null;
  }
}

function parseRecommendation(text: string): Omit<GTDRecommendation, 'aiGenerated'> | null {
  try {
    const match = text.match(/\{[\s\S]*\}/);
    if (!match) return null;
    const parsed = JSON.parse(match[0]) as Record<string, unknown>;
    if (typeof parsed.nextActionText !== 'string') return null;
    if (typeof parsed.reasoning !== 'string') return null;

    const validStatuses = ['open', 'in-progress', 'waiting', 'done', 'cancelled', 'archived'];
    const validEnergies = ['Quick', 'Medium', 'Deep'];

    return {
      nextActionText: parsed.nextActionText,
      suggestedStatus: validStatuses.includes(parsed.suggestedStatus as string)
        ? (parsed.suggestedStatus as GTDRecommendation['suggestedStatus'])
        : undefined,
      suggestedEnergy: validEnergies.includes(parsed.suggestedEnergy as string)
        ? (parsed.suggestedEnergy as GTDRecommendation['suggestedEnergy'])
        : undefined,
      suggestedContext: typeof parsed.suggestedContext === 'string' ? parsed.suggestedContext : undefined,
      suggestedTags: Array.isArray(parsed.suggestedTags)
        ? (parsed.suggestedTags as unknown[]).filter((t): t is string => typeof t === 'string')
        : undefined,
      reasoning: parsed.reasoning,
    };
  } catch {
    return null;
  }
}

// --- Cancellation ---

/**
 * Create a new AbortController for a GTD analysis session.
 * Cancels any previous in-flight session.
 */
export function createGTDAbortController(): AbortController {
  gtdAbortController?.abort();
  gtdAbortController = new AbortController();
  return gtdAbortController;
}

/**
 * Cancel any in-flight GTD analysis.
 */
export function cancelGTDAnalysis(): void {
  gtdAbortController?.abort();
  gtdAbortController = null;
}
